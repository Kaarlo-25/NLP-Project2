{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\valko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = text.translate(str.maketrans('', '', punctuation))  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "test = pd.read_excel(\"data\\\\test.xlsx\")\n",
    "test['Msg'] = test['Msg'].apply(clean_text)\n",
    "\n",
    "train = pd.read_excel(\"data\\\\train.xlsx\")\n",
    "train['Msg'] = train['Msg'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentoClassificacao\n",
      " 0    1114\n",
      "-1     653\n",
      "-2     262\n",
      " 1     256\n",
      "Name: count, dtype: int64\n",
      "-------------------\n",
      "SentimentoClassificacao\n",
      " 0    936\n",
      "-1    449\n",
      "-2    292\n",
      " 1    228\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['SentimentoClassificacao'].value_counts())\n",
    "print(\"-------------------\")\n",
    "print(test['SentimentoClassificacao'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog_ID                  0\n",
      "SentimentoRegressao        0\n",
      "SentimentoClassificacao    0\n",
      "Msg                        0\n",
      "dtype: int64\n",
      "----------------------\n",
      "Dialog_ID                  0\n",
      "Msg                        0\n",
      "Anotador1                  6\n",
      "Anotador2                  2\n",
      "SentimentoRegressao        0\n",
      "SentimentoClassificacao    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = train.isna().sum()\n",
    "print(nan_counts)\n",
    "print(\"----------------------\")\n",
    "nan_counts = test.isna().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of text: Bag-Of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[\"SentimentoClassificacao\"].values\n",
    "x_test = test[\"Msg\"].values\n",
    "y_train = train[\"SentimentoClassificacao\"].values\n",
    "x_train = train[\"Msg\"].values\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized x_train dataset length: 4456\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "print(f\"resized x_train dataset length: {x_train.shape[0]}\")\n",
    "x_train_2, x_val, y_train_2, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN for k=1 and w=uniform: 54.71%\n",
      "Accuracy of KNN for k=1 and w=distance: 54.71%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=2 and w=uniform: 45.18%\n",
      "Accuracy of KNN for k=2 and w=distance: 47.09%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=3 and w=uniform: 50.11%\n",
      "Accuracy of KNN for k=3 and w=distance: 51.91%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=4 and w=uniform: 49.22%\n",
      "Accuracy of KNN for k=4 and w=distance: 50.78%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=5 and w=uniform: 50.45%\n",
      "Accuracy of KNN for k=5 and w=distance: 52.91%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=6 and w=uniform: 48.43%\n",
      "Accuracy of KNN for k=6 and w=distance: 51.46%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=7 and w=uniform: 45.74%\n",
      "Accuracy of KNN for k=7 and w=distance: 48.43%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=8 and w=uniform: 46.52%\n",
      "Accuracy of KNN for k=8 and w=distance: 49.89%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=9 and w=uniform: 45.18%\n",
      "Accuracy of KNN for k=9 and w=distance: 49.44%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=10 and w=uniform: 46.08%\n",
      "Accuracy of KNN for k=10 and w=distance: 49.33%\n",
      "\n",
      "\n",
      "The best hyperparameters for Bag-of-Words are k=1 & w=uniform with 54.15%\n",
      "-------------\n",
      "Accuracy of SVM for c=1 and kernel=linear: 55.72%\n",
      "Accuracy of SVM for c=1 and kernel=poly: 38.0%\n",
      "Accuracy of SVM for c=1 and kernel=rbf: 58.3%\n",
      "Accuracy of SVM for c=1 and kernel=sigmoid: 53.92%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=2 and kernel=linear: 55.72%\n",
      "Accuracy of SVM for c=2 and kernel=poly: 39.69%\n",
      "Accuracy of SVM for c=2 and kernel=rbf: 56.61%\n",
      "Accuracy of SVM for c=2 and kernel=sigmoid: 53.81%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=3 and kernel=linear: 55.61%\n",
      "Accuracy of SVM for c=3 and kernel=poly: 41.93%\n",
      "Accuracy of SVM for c=3 and kernel=rbf: 56.5%\n",
      "Accuracy of SVM for c=3 and kernel=sigmoid: 52.91%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=4 and kernel=linear: 55.38%\n",
      "Accuracy of SVM for c=4 and kernel=poly: 43.83%\n",
      "Accuracy of SVM for c=4 and kernel=rbf: 55.94%\n",
      "Accuracy of SVM for c=4 and kernel=sigmoid: 53.59%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=5 and kernel=linear: 55.27%\n",
      "Accuracy of SVM for c=5 and kernel=poly: 43.39%\n",
      "Accuracy of SVM for c=5 and kernel=rbf: 56.05%\n",
      "Accuracy of SVM for c=5 and kernel=sigmoid: 52.58%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=6 and kernel=linear: 55.49%\n",
      "Accuracy of SVM for c=6 and kernel=poly: 43.72%\n",
      "Accuracy of SVM for c=6 and kernel=rbf: 56.28%\n",
      "Accuracy of SVM for c=6 and kernel=sigmoid: 52.69%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=7 and kernel=linear: 55.61%\n",
      "Accuracy of SVM for c=7 and kernel=poly: 44.84%\n",
      "Accuracy of SVM for c=7 and kernel=rbf: 56.39%\n",
      "Accuracy of SVM for c=7 and kernel=sigmoid: 52.8%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=8 and kernel=linear: 55.61%\n",
      "Accuracy of SVM for c=8 and kernel=poly: 45.18%\n",
      "Accuracy of SVM for c=8 and kernel=rbf: 56.28%\n",
      "Accuracy of SVM for c=8 and kernel=sigmoid: 51.23%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=9 and kernel=linear: 55.49%\n",
      "Accuracy of SVM for c=9 and kernel=poly: 45.29%\n",
      "Accuracy of SVM for c=9 and kernel=rbf: 56.17%\n",
      "Accuracy of SVM for c=9 and kernel=sigmoid: 49.66%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=10 and kernel=linear: 55.61%\n",
      "Accuracy of SVM for c=10 and kernel=poly: 45.74%\n",
      "Accuracy of SVM for c=10 and kernel=rbf: 56.28%\n",
      "Accuracy of SVM for c=10 and kernel=sigmoid: 51.79%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=11 and kernel=linear: 55.49%\n",
      "Accuracy of SVM for c=11 and kernel=poly: 45.85%\n",
      "Accuracy of SVM for c=11 and kernel=rbf: 56.28%\n",
      "Accuracy of SVM for c=11 and kernel=sigmoid: 51.91%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=12 and kernel=linear: 55.49%\n",
      "Accuracy of SVM for c=12 and kernel=poly: 46.08%\n",
      "Accuracy of SVM for c=12 and kernel=rbf: 56.61%\n",
      "Accuracy of SVM for c=12 and kernel=sigmoid: 51.01%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=13 and kernel=linear: 55.49%\n",
      "Accuracy of SVM for c=13 and kernel=poly: 47.31%\n",
      "Accuracy of SVM for c=13 and kernel=rbf: 57.51%\n",
      "Accuracy of SVM for c=13 and kernel=sigmoid: 50.9%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=14 and kernel=linear: 55.61%\n",
      "Accuracy of SVM for c=14 and kernel=poly: 47.42%\n",
      "Accuracy of SVM for c=14 and kernel=rbf: 57.4%\n",
      "Accuracy of SVM for c=14 and kernel=sigmoid: 49.55%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=15 and kernel=linear: 55.61%\n",
      "Accuracy of SVM for c=15 and kernel=poly: 47.98%\n",
      "Accuracy of SVM for c=15 and kernel=rbf: 57.4%\n",
      "Accuracy of SVM for c=15 and kernel=sigmoid: 50.34%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=16 and kernel=linear: 55.72%\n",
      "Accuracy of SVM for c=16 and kernel=poly: 47.87%\n",
      "Accuracy of SVM for c=16 and kernel=rbf: 57.29%\n",
      "Accuracy of SVM for c=16 and kernel=sigmoid: 50.22%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=17 and kernel=linear: 55.61%\n",
      "Accuracy of SVM for c=17 and kernel=poly: 47.87%\n",
      "Accuracy of SVM for c=17 and kernel=rbf: 57.17%\n",
      "Accuracy of SVM for c=17 and kernel=sigmoid: 49.44%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=18 and kernel=linear: 55.72%\n",
      "Accuracy of SVM for c=18 and kernel=poly: 47.98%\n",
      "Accuracy of SVM for c=18 and kernel=rbf: 57.17%\n",
      "Accuracy of SVM for c=18 and kernel=sigmoid: 51.12%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=19 and kernel=linear: 55.72%\n",
      "Accuracy of SVM for c=19 and kernel=poly: 48.09%\n",
      "Accuracy of SVM for c=19 and kernel=rbf: 57.29%\n",
      "Accuracy of SVM for c=19 and kernel=sigmoid: 50.56%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=20 and kernel=linear: 55.61%\n",
      "Accuracy of SVM for c=20 and kernel=poly: 48.32%\n",
      "Accuracy of SVM for c=20 and kernel=rbf: 56.95%\n",
      "Accuracy of SVM for c=20 and kernel=sigmoid: 50.34%\n",
      "\n",
      "\n",
      "The best hyperparameters for Bag-of-Words are c=1 & kernel=rbf with 58.18%\n",
      "-------------\n",
      "Accuracy for criterion=gini and depth=1: 26.79%\n",
      "Accuracy for criterion=gini and depth=2: 30.16%\n",
      "Accuracy for criterion=gini and depth=3: 32.96%\n",
      "Accuracy for criterion=gini and depth=4: 34.75%\n",
      "Accuracy for criterion=gini and depth=5: 36.77%\n",
      "Accuracy for criterion=gini and depth=6: 38.45%\n",
      "Accuracy for criterion=gini and depth=7: 39.46%\n",
      "Accuracy for criterion=gini and depth=8: 39.91%\n",
      "Accuracy for criterion=gini and depth=9: 41.26%\n",
      "Accuracy for criterion=gini and depth=10: 41.59%\n",
      "Accuracy for criterion=gini and depth=11: 41.48%\n",
      "Accuracy for criterion=gini and depth=12: 42.6%\n",
      "Accuracy for criterion=gini and depth=13: 43.5%\n",
      "Accuracy for criterion=gini and depth=14: 44.06%\n",
      "Accuracy for criterion=gini and depth=15: 45.4%\n",
      "Accuracy for criterion=gini and depth=16: 45.96%\n",
      "Accuracy for criterion=gini and depth=17: 46.41%\n",
      "Accuracy for criterion=gini and depth=18: 46.64%\n",
      "Accuracy for criterion=gini and depth=19: 47.2%\n",
      "Accuracy for criterion=gini and depth=20: 45.74%\n",
      "\n",
      "\n",
      "Accuracy for criterion=entropy and depth=1: 27.91%\n",
      "Accuracy for criterion=entropy and depth=2: 31.17%\n",
      "Accuracy for criterion=entropy and depth=3: 34.98%\n",
      "Accuracy for criterion=entropy and depth=4: 36.55%\n",
      "Accuracy for criterion=entropy and depth=5: 36.88%\n",
      "Accuracy for criterion=entropy and depth=6: 38.9%\n",
      "Accuracy for criterion=entropy and depth=7: 39.91%\n",
      "Accuracy for criterion=entropy and depth=8: 41.82%\n",
      "Accuracy for criterion=entropy and depth=9: 42.71%\n",
      "Accuracy for criterion=entropy and depth=10: 43.61%\n",
      "Accuracy for criterion=entropy and depth=11: 43.5%\n",
      "Accuracy for criterion=entropy and depth=12: 44.73%\n",
      "Accuracy for criterion=entropy and depth=13: 45.52%\n",
      "Accuracy for criterion=entropy and depth=14: 46.08%\n",
      "Accuracy for criterion=entropy and depth=15: 46.19%\n",
      "Accuracy for criterion=entropy and depth=16: 46.19%\n",
      "Accuracy for criterion=entropy and depth=17: 45.74%\n",
      "Accuracy for criterion=entropy and depth=18: 46.75%\n",
      "Accuracy for criterion=entropy and depth=19: 46.52%\n",
      "Accuracy for criterion=entropy and depth=20: 46.19%\n",
      "\n",
      "\n",
      "Accuracy for criterion=log_loss and depth=1: 27.91%\n",
      "Accuracy for criterion=log_loss and depth=2: 31.17%\n",
      "Accuracy for criterion=log_loss and depth=3: 34.98%\n",
      "Accuracy for criterion=log_loss and depth=4: 36.55%\n",
      "Accuracy for criterion=log_loss and depth=5: 37.0%\n",
      "Accuracy for criterion=log_loss and depth=6: 39.01%\n",
      "Accuracy for criterion=log_loss and depth=7: 40.02%\n",
      "Accuracy for criterion=log_loss and depth=8: 41.82%\n",
      "Accuracy for criterion=log_loss and depth=9: 42.6%\n",
      "Accuracy for criterion=log_loss and depth=10: 43.5%\n",
      "Accuracy for criterion=log_loss and depth=11: 43.83%\n",
      "Accuracy for criterion=log_loss and depth=12: 45.07%\n",
      "Accuracy for criterion=log_loss and depth=13: 45.4%\n",
      "Accuracy for criterion=log_loss and depth=14: 46.08%\n",
      "Accuracy for criterion=log_loss and depth=15: 46.3%\n",
      "Accuracy for criterion=log_loss and depth=16: 46.08%\n",
      "Accuracy for criterion=log_loss and depth=17: 45.63%\n",
      "Accuracy for criterion=log_loss and depth=18: 46.97%\n",
      "Accuracy for criterion=log_loss and depth=19: 46.19%\n",
      "Accuracy for criterion=log_loss and depth=20: 46.3%\n",
      "\n",
      "\n",
      "The best hyperparameters for Bag-of-Words are criterion=gini & depth=19 with 46.86%\n"
     ]
    }
   ],
   "source": [
    "weights = ['uniform', 'distance']\n",
    "for k in range(1, 11):\n",
    "    for w in weights:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "        clf.fit(x_train_2, y_train_2)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        accuracy = round(accuracy_score(y_val, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of KNN for k={k} and w={w}: {accuracy}%\")\n",
    "    print(\"\\n\")\n",
    "print(\"The best hyperparameters for Bag-of-Words are k=1 & w=uniform with 54.15%\")\n",
    "print(\"-------------\")\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for c in range(1, 21):\n",
    "    for k in kernels:\n",
    "        clf = SVC(C=c, kernel=k)\n",
    "        clf.fit(x_train_2, y_train_2)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        accuracy = round(accuracy_score(y_val, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of SVM for c={c} and kernel={k}: {accuracy}%\")\n",
    "    print(\"\\n\")\n",
    "print(\"The best hyperparameters for Bag-of-Words are c=1 & kernel=rbf with 58.18%\")\n",
    "print(\"-------------\")\n",
    "\n",
    "criterions = ['gini', 'entropy', 'log_loss']\n",
    "for criterion in criterions:\n",
    "\tfor depth in range(1, 21):\n",
    "\t\ttree = DecisionTreeClassifier(criterion=criterion, max_depth=depth)\n",
    "\t\ttree.fit(x_train_2, y_train_2)\n",
    "\t\ty_pred = tree.predict(x_val)\n",
    "\t\taccuracy = round(accuracy_score(y_val, y_pred)*100, 2)\n",
    "\t\tprint(f\"Accuracy for criterion={criterion} and depth={depth}: {accuracy}%\")\n",
    "\tprint(\"\\n\")\n",
    "print(\"The best hyperparameters for Bag-of-Words are criterion=gini & depth=19 with 46.86%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classifiers(k: int, w: str, c: int, kernel: str, criterion: str, depth: int, Neg_x_values: bool = False):\n",
    "\tknn = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "\tknn.fit(x_train, y_train)\n",
    "\ty_pred = knn.predict(x_test)\n",
    "\taccuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\tprint(f\"Accuracy of KNN: {accuracy}%\")\n",
    "\tprint(classification_report(y_test, y_pred))\n",
    "\n",
    "\tsvm = SVC(C=c, kernel=kernel)\n",
    "\tsvm.fit(x_train, y_train)\n",
    "\ty_pred = svm.predict(x_test)\n",
    "\taccuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\tprint(f\"Accuracy of SVM: {accuracy}%\")\n",
    "\tprint(classification_report(y_test, y_pred))\n",
    "\n",
    "\ttree = DecisionTreeClassifier(criterion=criterion, max_depth=depth)\n",
    "\ttree.fit(x_train, y_train)\n",
    "\ty_pred = tree.predict(x_test)\n",
    "\taccuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\tprint(f\"Accuracy of tree: {accuracy}%\")\n",
    "\tprint(classification_report(y_test, y_pred))\n",
    "\n",
    "\trandom_forest = RandomForestClassifier()\n",
    "\trandom_forest.fit(x_train, y_train)\n",
    "\ty_pred = random_forest.predict(x_test)\n",
    "\taccuracy_rf = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "\tprint(f\"Accuracy for Random Forest: {accuracy}%\")\n",
    "\tprint(classification_report(y_test, y_pred))\n",
    "\n",
    "\tbagging = BaggingClassifier()\n",
    "\tbagging.fit(x_train, y_train)\n",
    "\ty_pred_bagging = bagging.predict(x_test)\n",
    "\taccuracy_bagging = round(accuracy_score(y_test, y_pred_bagging) * 100, 2)\n",
    "\tprint(f\"Accuracy for Bagging: {accuracy_bagging}%\")\n",
    "\tprint(classification_report(y_test, y_pred_bagging))\n",
    "\n",
    "\tlogistic = LogisticRegression()\n",
    "\tlogistic.fit(x_train, y_train)\n",
    "\ty_pred = logistic.predict(x_test)\n",
    "\taccuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\tprint(f\"Accuracy for Logistic: {accuracy}%\")\n",
    "\tprint(classification_report(y_test, y_pred))\n",
    "\n",
    "\tperceptron = Perceptron()\n",
    "\tperceptron.fit(x_train, y_train)\n",
    "\ty_pred = perceptron.predict(x_test)\n",
    "\taccuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\tprint(f\"Accuracy for Perceptron: {accuracy}%\")\n",
    "\tprint(classification_report(y_test, y_pred))\n",
    "\n",
    "\tbernoulli = BernoulliNB()\n",
    "\tbernoulli.fit(x_train, y_train)\n",
    "\ty_pred = bernoulli.predict(x_test)\n",
    "\taccuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\tprint(f\"Accuracy of bernoulliNB: {accuracy}%\")\n",
    "\tprint(classification_report(y_test, y_pred))\n",
    "\n",
    "\tif not Neg_x_values:\n",
    "\t\tmulti = MultinomialNB()\n",
    "\t\tmulti.fit(x_train, y_train)\n",
    "\t\ty_pred = multi.predict(x_test)\n",
    "\t\taccuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\t\tprint(f\"Accuracy of multinomialNB: {accuracy}%\")\n",
    "\t\tprint(classification_report(y_test, y_pred))\n",
    "\n",
    "\t\tstacking = StackingClassifier(\n",
    "\t\t\testimators=[\n",
    "\t\t\t\t('logistic', LogisticRegression()),\t\t\n",
    "\t\t\t\t('svm', SVC(C=1, kernel=\"rbf\")),\t\t\n",
    "\t\t\t\t(\"tree\", DecisionTreeClassifier(criterion=\"gini\", max_depth=19)),\t\n",
    "\t\t\t\t(\"Bernoulli\", BernoulliNB()),\t\t\t\n",
    "\t\t\t\t(\"Multinomial\", MultinomialNB())\t\t\n",
    "\t\t\t],\n",
    "\t\t\tfinal_estimator=SVC(C=1, kernel=\"rbf\"))\n",
    "\t\tstacking.fit(x_train, y_train)\n",
    "\t\ty_pred_stacking = stacking.predict(x_test)\n",
    "\t\taccuracy_stacking = round(accuracy_score(y_test, y_pred_stacking) * 100, 2)\n",
    "\t\tprint(f\"Accuracy for Stacking: {accuracy_stacking}%\")\n",
    "\t\tprint(classification_report(y_test, y_pred_stacking))\n",
    "\n",
    "\tx_train_dense = x_train.toarray() if hasattr(x_train, \"toarray\") else x_train\n",
    "\ty_train_dense = y_train.toarray() if hasattr(y_train, \"toarray\") else y_train\n",
    "\tx_test_dense = x_test.toarray() if hasattr(x_test, \"toarray\") else x_test\n",
    "\ty_test_dense = y_test.toarray() if hasattr(y_test, \"toarray\") else y_test\n",
    "\n",
    "\tgauss = GaussianNB()\n",
    "\tgauss.fit(x_train_dense, y_train_dense)\n",
    "\ty_pred = gauss.predict(x_test_dense)\n",
    "\taccuracy = round(accuracy_score(y_test_dense, y_pred)*100, 2)\n",
    "\tprint(f\"Accuracy of gaussianNB: {accuracy}%\")\n",
    "\tprint(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 35.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.27      0.40      0.32       292\n",
      "          -1       0.30      0.47      0.37       449\n",
      "           0       0.59      0.33      0.42       936\n",
      "           1       0.15      0.16      0.15       228\n",
      "\n",
      "    accuracy                           0.35      1905\n",
      "   macro avg       0.33      0.34      0.32      1905\n",
      "weighted avg       0.42      0.35      0.36      1905\n",
      "\n",
      "Accuracy of SVM: 46.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.35      0.19      0.25       292\n",
      "          -1       0.39      0.35      0.37       449\n",
      "           0       0.58      0.65      0.62       936\n",
      "           1       0.22      0.29      0.25       228\n",
      "\n",
      "    accuracy                           0.47      1905\n",
      "   macro avg       0.39      0.37      0.37      1905\n",
      "weighted avg       0.46      0.47      0.46      1905\n",
      "\n",
      "Accuracy of tree: 28.29%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.43      0.05      0.10       292\n",
      "          -1       0.33      0.16      0.21       449\n",
      "           0       0.66      0.34      0.45       936\n",
      "           1       0.11      0.58      0.19       228\n",
      "\n",
      "    accuracy                           0.28      1905\n",
      "   macro avg       0.38      0.28      0.24      1905\n",
      "weighted avg       0.48      0.28      0.31      1905\n",
      "\n",
      "Accuracy for Random Forest: 28.29%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.43      0.28      0.34       292\n",
      "          -1       0.36      0.46      0.40       449\n",
      "           0       0.69      0.53      0.60       936\n",
      "           1       0.22      0.40      0.29       228\n",
      "\n",
      "    accuracy                           0.46      1905\n",
      "   macro avg       0.42      0.42      0.41      1905\n",
      "weighted avg       0.51      0.46      0.48      1905\n",
      "\n",
      "Accuracy for Bagging: 42.15%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.32      0.25      0.28       292\n",
      "          -1       0.34      0.41      0.37       449\n",
      "           0       0.65      0.49      0.56       936\n",
      "           1       0.21      0.39      0.27       228\n",
      "\n",
      "    accuracy                           0.42      1905\n",
      "   macro avg       0.38      0.38      0.37      1905\n",
      "weighted avg       0.47      0.42      0.44      1905\n",
      "\n",
      "Accuracy for Logistic: 43.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.31      0.23      0.26       292\n",
      "          -1       0.38      0.46      0.41       449\n",
      "           0       0.62      0.51      0.56       936\n",
      "           1       0.21      0.35      0.26       228\n",
      "\n",
      "    accuracy                           0.44      1905\n",
      "   macro avg       0.38      0.39      0.38      1905\n",
      "weighted avg       0.47      0.44      0.45      1905\n",
      "\n",
      "Accuracy for Perceptron: 44.3%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.30      0.23      0.26       292\n",
      "          -1       0.35      0.49      0.41       449\n",
      "           0       0.63      0.56      0.59       936\n",
      "           1       0.16      0.16      0.16       228\n",
      "\n",
      "    accuracy                           0.44      1905\n",
      "   macro avg       0.36      0.36      0.35      1905\n",
      "weighted avg       0.46      0.44      0.45      1905\n",
      "\n",
      "Accuracy of bernoulliNB: 38.06%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.33      0.39      0.36       292\n",
      "          -1       0.34      0.34      0.34       449\n",
      "           0       0.73      0.32      0.45       936\n",
      "           1       0.22      0.68      0.34       228\n",
      "\n",
      "    accuracy                           0.38      1905\n",
      "   macro avg       0.41      0.43      0.37      1905\n",
      "weighted avg       0.51      0.38      0.40      1905\n",
      "\n",
      "Accuracy of multinomialNB: 49.45%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.43      0.37      0.40       292\n",
      "          -1       0.34      0.51      0.41       449\n",
      "           0       0.76      0.57      0.65       936\n",
      "           1       0.26      0.32      0.29       228\n",
      "\n",
      "    accuracy                           0.49      1905\n",
      "   macro avg       0.45      0.44      0.44      1905\n",
      "weighted avg       0.55      0.49      0.51      1905\n",
      "\n",
      "Accuracy for Stacking: 45.98%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.38      0.18      0.25       292\n",
      "          -1       0.36      0.37      0.36       449\n",
      "           0       0.57      0.64      0.60       936\n",
      "           1       0.22      0.25      0.23       228\n",
      "\n",
      "    accuracy                           0.46      1905\n",
      "   macro avg       0.38      0.36      0.36      1905\n",
      "weighted avg       0.45      0.46      0.45      1905\n",
      "\n",
      "Accuracy of gaussianNB: 41.84%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.30      0.21      0.24       292\n",
      "          -1       0.31      0.44      0.37       449\n",
      "           0       0.58      0.47      0.52       936\n",
      "           1       0.31      0.41      0.35       228\n",
      "\n",
      "    accuracy                           0.42      1905\n",
      "   macro avg       0.38      0.38      0.37      1905\n",
      "weighted avg       0.44      0.42      0.42      1905\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(compare_classifiers(1, \"uniform\", 1, \"rbf\", \"gini\", 19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of text: Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\valko\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "y_test = test[\"SentimentoClassificacao\"].values\n",
    "x_test = test[\"Msg\"].values\n",
    "y_train = train[\"SentimentoClassificacao\"].values\n",
    "x_train = train[\"Msg\"].values\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "train_sentences = [word_tokenize(text.lower()) for text in x_train]\n",
    "test_sentences = [word_tokenize(text.lower()) for text in x_test]\n",
    "model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "def get_sentence_vector(sentence):\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    word_vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "x_train = np.array([get_sentence_vector(text) for text in x_train])\n",
    "x_test = np.array([get_sentence_vector(text) for text in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized x_train dataset length: 4456\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "print(f\"resized x_train dataset length: {x_train.shape[0]}\")\n",
    "x_train_2, x_val, y_train_2, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN for k=1 and w=uniform: 77.91%\n",
      "Accuracy of KNN for k=1 and w=distance: 77.91%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=2 and w=uniform: 71.97%\n",
      "Accuracy of KNN for k=2 and w=distance: 78.03%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=3 and w=uniform: 71.86%\n",
      "Accuracy of KNN for k=3 and w=distance: 75.34%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=4 and w=uniform: 69.06%\n",
      "Accuracy of KNN for k=4 and w=distance: 75.34%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=5 and w=uniform: 68.05%\n",
      "Accuracy of KNN for k=5 and w=distance: 73.88%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=6 and w=uniform: 66.03%\n",
      "Accuracy of KNN for k=6 and w=distance: 73.65%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=7 and w=uniform: 65.7%\n",
      "Accuracy of KNN for k=7 and w=distance: 72.76%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=8 and w=uniform: 64.57%\n",
      "Accuracy of KNN for k=8 and w=distance: 71.97%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=9 and w=uniform: 63.45%\n",
      "Accuracy of KNN for k=9 and w=distance: 71.3%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=10 and w=uniform: 61.21%\n",
      "Accuracy of KNN for k=10 and w=distance: 70.52%\n",
      "\n",
      "\n",
      "The best hyperparameters for Word2Vec are k=1 & w=distance with 78.03%\n",
      "-------------\n",
      "Accuracy of SVM for c=1 and kernel=linear: 33.52%\n",
      "Accuracy of SVM for c=1 and kernel=poly: 32.17%\n",
      "Accuracy of SVM for c=1 and kernel=rbf: 36.21%\n",
      "Accuracy of SVM for c=1 and kernel=sigmoid: 25.22%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=2 and kernel=linear: 35.2%\n",
      "Accuracy of SVM for c=2 and kernel=poly: 33.97%\n",
      "Accuracy of SVM for c=2 and kernel=rbf: 38.79%\n",
      "Accuracy of SVM for c=2 and kernel=sigmoid: 25.11%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=3 and kernel=linear: 34.98%\n",
      "Accuracy of SVM for c=3 and kernel=poly: 35.54%\n",
      "Accuracy of SVM for c=3 and kernel=rbf: 40.92%\n",
      "Accuracy of SVM for c=3 and kernel=sigmoid: 25.0%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=4 and kernel=linear: 35.65%\n",
      "Accuracy of SVM for c=4 and kernel=poly: 36.55%\n",
      "Accuracy of SVM for c=4 and kernel=rbf: 42.49%\n",
      "Accuracy of SVM for c=4 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=5 and kernel=linear: 35.87%\n",
      "Accuracy of SVM for c=5 and kernel=poly: 37.56%\n",
      "Accuracy of SVM for c=5 and kernel=rbf: 43.72%\n",
      "Accuracy of SVM for c=5 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=6 and kernel=linear: 36.66%\n",
      "Accuracy of SVM for c=6 and kernel=poly: 38.45%\n",
      "Accuracy of SVM for c=6 and kernel=rbf: 45.29%\n",
      "Accuracy of SVM for c=6 and kernel=sigmoid: 24.78%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=7 and kernel=linear: 36.88%\n",
      "Accuracy of SVM for c=7 and kernel=poly: 38.57%\n",
      "Accuracy of SVM for c=7 and kernel=rbf: 46.75%\n",
      "Accuracy of SVM for c=7 and kernel=sigmoid: 24.78%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=8 and kernel=linear: 37.0%\n",
      "Accuracy of SVM for c=8 and kernel=poly: 39.24%\n",
      "Accuracy of SVM for c=8 and kernel=rbf: 47.42%\n",
      "Accuracy of SVM for c=8 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=9 and kernel=linear: 37.0%\n",
      "Accuracy of SVM for c=9 and kernel=poly: 40.02%\n",
      "Accuracy of SVM for c=9 and kernel=rbf: 48.32%\n",
      "Accuracy of SVM for c=9 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=10 and kernel=linear: 37.11%\n",
      "Accuracy of SVM for c=10 and kernel=poly: 40.47%\n",
      "Accuracy of SVM for c=10 and kernel=rbf: 49.55%\n",
      "Accuracy of SVM for c=10 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=11 and kernel=linear: 37.44%\n",
      "Accuracy of SVM for c=11 and kernel=poly: 40.7%\n",
      "Accuracy of SVM for c=11 and kernel=rbf: 50.45%\n",
      "Accuracy of SVM for c=11 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=12 and kernel=linear: 37.89%\n",
      "Accuracy of SVM for c=12 and kernel=poly: 41.48%\n",
      "Accuracy of SVM for c=12 and kernel=rbf: 51.12%\n",
      "Accuracy of SVM for c=12 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=13 and kernel=linear: 38.34%\n",
      "Accuracy of SVM for c=13 and kernel=poly: 41.7%\n",
      "Accuracy of SVM for c=13 and kernel=rbf: 51.23%\n",
      "Accuracy of SVM for c=13 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=14 and kernel=linear: 38.23%\n",
      "Accuracy of SVM for c=14 and kernel=poly: 41.7%\n",
      "Accuracy of SVM for c=14 and kernel=rbf: 52.02%\n",
      "Accuracy of SVM for c=14 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=15 and kernel=linear: 38.57%\n",
      "Accuracy of SVM for c=15 and kernel=poly: 41.82%\n",
      "Accuracy of SVM for c=15 and kernel=rbf: 52.91%\n",
      "Accuracy of SVM for c=15 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=16 and kernel=linear: 38.57%\n",
      "Accuracy of SVM for c=16 and kernel=poly: 41.59%\n",
      "Accuracy of SVM for c=16 and kernel=rbf: 53.14%\n",
      "Accuracy of SVM for c=16 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=17 and kernel=linear: 38.9%\n",
      "Accuracy of SVM for c=17 and kernel=poly: 41.59%\n",
      "Accuracy of SVM for c=17 and kernel=rbf: 53.03%\n",
      "Accuracy of SVM for c=17 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=18 and kernel=linear: 39.01%\n",
      "Accuracy of SVM for c=18 and kernel=poly: 42.04%\n",
      "Accuracy of SVM for c=18 and kernel=rbf: 53.36%\n",
      "Accuracy of SVM for c=18 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=19 and kernel=linear: 39.01%\n",
      "Accuracy of SVM for c=19 and kernel=poly: 41.82%\n",
      "Accuracy of SVM for c=19 and kernel=rbf: 53.25%\n",
      "Accuracy of SVM for c=19 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=20 and kernel=linear: 39.01%\n",
      "Accuracy of SVM for c=20 and kernel=poly: 41.82%\n",
      "Accuracy of SVM for c=20 and kernel=rbf: 53.25%\n",
      "Accuracy of SVM for c=20 and kernel=sigmoid: 24.89%\n",
      "\n",
      "\n",
      "The best hyperparameters for Word2Vec are c=20 & kernel=rbf with 54.93%\n",
      "-------------\n",
      "Accuracy for criterion=gini and depth=1: 28.92%\n",
      "Accuracy for criterion=gini and depth=2: 32.4%\n",
      "Accuracy for criterion=gini and depth=3: 37.89%\n",
      "Accuracy for criterion=gini and depth=4: 38.12%\n",
      "Accuracy for criterion=gini and depth=5: 43.95%\n",
      "Accuracy for criterion=gini and depth=6: 45.4%\n",
      "Accuracy for criterion=gini and depth=7: 50.22%\n",
      "Accuracy for criterion=gini and depth=8: 50.67%\n",
      "Accuracy for criterion=gini and depth=9: 53.59%\n",
      "Accuracy for criterion=gini and depth=10: 57.06%\n",
      "Accuracy for criterion=gini and depth=11: 59.53%\n",
      "Accuracy for criterion=gini and depth=12: 60.31%\n",
      "Accuracy for criterion=gini and depth=13: 61.21%\n",
      "Accuracy for criterion=gini and depth=14: 62.11%\n",
      "Accuracy for criterion=gini and depth=15: 61.55%\n",
      "Accuracy for criterion=gini and depth=16: 63.9%\n",
      "Accuracy for criterion=gini and depth=17: 64.46%\n",
      "Accuracy for criterion=gini and depth=18: 63.0%\n",
      "Accuracy for criterion=gini and depth=19: 63.23%\n",
      "Accuracy for criterion=gini and depth=20: 63.79%\n",
      "\n",
      "\n",
      "Accuracy for criterion=entropy and depth=1: 28.92%\n",
      "Accuracy for criterion=entropy and depth=2: 32.96%\n",
      "Accuracy for criterion=entropy and depth=3: 35.31%\n",
      "Accuracy for criterion=entropy and depth=4: 38.23%\n",
      "Accuracy for criterion=entropy and depth=5: 42.38%\n",
      "Accuracy for criterion=entropy and depth=6: 43.16%\n",
      "Accuracy for criterion=entropy and depth=7: 46.64%\n",
      "Accuracy for criterion=entropy and depth=8: 51.68%\n",
      "Accuracy for criterion=entropy and depth=9: 54.04%\n",
      "Accuracy for criterion=entropy and depth=10: 56.39%\n",
      "Accuracy for criterion=entropy and depth=11: 57.4%\n",
      "Accuracy for criterion=entropy and depth=12: 60.54%\n",
      "Accuracy for criterion=entropy and depth=13: 60.99%\n",
      "Accuracy for criterion=entropy and depth=14: 62.11%\n",
      "Accuracy for criterion=entropy and depth=15: 63.45%\n",
      "Accuracy for criterion=entropy and depth=16: 62.89%\n",
      "Accuracy for criterion=entropy and depth=17: 62.89%\n",
      "Accuracy for criterion=entropy and depth=18: 64.35%\n",
      "Accuracy for criterion=entropy and depth=19: 63.68%\n",
      "Accuracy for criterion=entropy and depth=20: 63.0%\n",
      "\n",
      "\n",
      "Accuracy for criterion=log_loss and depth=1: 28.92%\n",
      "Accuracy for criterion=log_loss and depth=2: 32.96%\n",
      "Accuracy for criterion=log_loss and depth=3: 35.31%\n",
      "Accuracy for criterion=log_loss and depth=4: 38.12%\n",
      "Accuracy for criterion=log_loss and depth=5: 42.26%\n",
      "Accuracy for criterion=log_loss and depth=6: 42.83%\n",
      "Accuracy for criterion=log_loss and depth=7: 46.3%\n",
      "Accuracy for criterion=log_loss and depth=8: 51.57%\n",
      "Accuracy for criterion=log_loss and depth=9: 53.7%\n",
      "Accuracy for criterion=log_loss and depth=10: 56.95%\n",
      "Accuracy for criterion=log_loss and depth=11: 57.4%\n",
      "Accuracy for criterion=log_loss and depth=12: 58.18%\n",
      "Accuracy for criterion=log_loss and depth=13: 60.65%\n",
      "Accuracy for criterion=log_loss and depth=14: 62.44%\n",
      "Accuracy for criterion=log_loss and depth=15: 63.57%\n",
      "Accuracy for criterion=log_loss and depth=16: 63.79%\n",
      "Accuracy for criterion=log_loss and depth=17: 64.13%\n",
      "Accuracy for criterion=log_loss and depth=18: 63.0%\n",
      "Accuracy for criterion=log_loss and depth=19: 64.13%\n",
      "Accuracy for criterion=log_loss and depth=20: 63.0%\n",
      "\n",
      "\n",
      "The best hyperparameters for Word2Vec are criterion=gini & depth=19 with 65.81%\n"
     ]
    }
   ],
   "source": [
    "weights = ['uniform', 'distance']\n",
    "for k in range(1, 11):\n",
    "    for w in weights:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "        clf.fit(x_train_2, y_train_2)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        accuracy = round(accuracy_score(y_val, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of KNN for k={k} and w={w}: {accuracy}%\")\n",
    "    print(\"\\n\")\n",
    "print(\"The best hyperparameters for Word2Vec are k=1 & w=distance with 78.03%\")\n",
    "print(\"-------------\")\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for c in range(1, 21):\n",
    "    for k in kernels:\n",
    "        clf = SVC(C=c, kernel=k)\n",
    "        clf.fit(x_train_2, y_train_2)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        accuracy = round(accuracy_score(y_val, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of SVM for c={c} and kernel={k}: {accuracy}%\")\n",
    "    print(\"\\n\")\n",
    "print(\"The best hyperparameters for Word2Vec are c=20 & kernel=rbf with 54.93%\")\n",
    "print(\"-------------\")\n",
    "\n",
    "criterions = ['gini', 'entropy', 'log_loss']\n",
    "for criterion in criterions:\n",
    "\tfor depth in range(1, 21):\n",
    "\t\ttree = DecisionTreeClassifier(criterion=criterion, max_depth=depth)\n",
    "\t\ttree.fit(x_train_2, y_train_2)\n",
    "\t\ty_pred = tree.predict(x_val)\n",
    "\t\taccuracy = round(accuracy_score(y_val, y_pred)*100, 2)\n",
    "\t\tprint(f\"Accuracy for criterion={criterion} and depth={depth}: {accuracy}%\")\n",
    "\tprint(\"\\n\")\n",
    "print(\"The best hyperparameters for Word2Vec are criterion=gini & depth=19 with 65.81%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 35.28%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.25      0.35      0.29       292\n",
      "          -1       0.31      0.38      0.34       449\n",
      "           0       0.62      0.35      0.45       936\n",
      "           1       0.17      0.30      0.22       228\n",
      "\n",
      "    accuracy                           0.35      1905\n",
      "   macro avg       0.34      0.34      0.32      1905\n",
      "weighted avg       0.44      0.35      0.37      1905\n",
      "\n",
      "Accuracy of SVM: 36.85%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.29      0.37      0.33       292\n",
      "          -1       0.28      0.30      0.29       449\n",
      "           0       0.66      0.36      0.47       936\n",
      "           1       0.22      0.52      0.31       228\n",
      "\n",
      "    accuracy                           0.37      1905\n",
      "   macro avg       0.36      0.39      0.35      1905\n",
      "weighted avg       0.46      0.37      0.39      1905\n",
      "\n",
      "Accuracy of tree: 36.01%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.26      0.23      0.24       292\n",
      "          -1       0.29      0.31      0.30       449\n",
      "           0       0.54      0.45      0.49       936\n",
      "           1       0.16      0.27      0.20       228\n",
      "\n",
      "    accuracy                           0.36      1905\n",
      "   macro avg       0.31      0.31      0.31      1905\n",
      "weighted avg       0.39      0.36      0.37      1905\n",
      "\n",
      "Accuracy for Random Forest: 36.01%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.40      0.22      0.28       292\n",
      "          -1       0.31      0.45      0.37       449\n",
      "           0       0.60      0.60      0.60       936\n",
      "           1       0.32      0.25      0.28       228\n",
      "\n",
      "    accuracy                           0.46      1905\n",
      "   macro avg       0.41      0.38      0.38      1905\n",
      "weighted avg       0.47      0.46      0.46      1905\n",
      "\n",
      "Accuracy for Bagging: 42.57%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.31      0.25      0.28       292\n",
      "          -1       0.29      0.41      0.34       449\n",
      "           0       0.60      0.53      0.56       936\n",
      "           1       0.28      0.25      0.27       228\n",
      "\n",
      "    accuracy                           0.43      1905\n",
      "   macro avg       0.37      0.36      0.36      1905\n",
      "weighted avg       0.44      0.43      0.43      1905\n",
      "\n",
      "Accuracy for Logistic: 20.94%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.20      0.09      0.13       292\n",
      "          -1       0.22      0.37      0.28       449\n",
      "           0       0.58      0.10      0.17       936\n",
      "           1       0.13      0.49      0.20       228\n",
      "\n",
      "    accuracy                           0.21      1905\n",
      "   macro avg       0.28      0.26      0.20      1905\n",
      "weighted avg       0.38      0.21      0.19      1905\n",
      "\n",
      "Accuracy for Perceptron: 16.59%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.16      0.99      0.27       292\n",
      "          -1       0.21      0.01      0.02       449\n",
      "           0       0.78      0.02      0.04       936\n",
      "           1       0.00      0.00      0.00       228\n",
      "\n",
      "    accuracy                           0.17      1905\n",
      "   macro avg       0.29      0.26      0.08      1905\n",
      "weighted avg       0.46      0.17      0.07      1905\n",
      "\n",
      "Accuracy of bernoulliNB: 27.35%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.20      0.68      0.31       292\n",
      "          -1       0.23      0.14      0.17       449\n",
      "           0       0.57      0.22      0.32       936\n",
      "           1       0.19      0.22      0.20       228\n",
      "\n",
      "    accuracy                           0.27      1905\n",
      "   macro avg       0.30      0.32      0.25      1905\n",
      "weighted avg       0.39      0.27      0.27      1905\n",
      "\n",
      "Accuracy of gaussianNB: 24.04%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.21      0.49      0.29       292\n",
      "          -1       0.23      0.15      0.18       449\n",
      "           0       0.57      0.17      0.27       936\n",
      "           1       0.13      0.39      0.20       228\n",
      "\n",
      "    accuracy                           0.24      1905\n",
      "   macro avg       0.29      0.30      0.23      1905\n",
      "weighted avg       0.38      0.24      0.24      1905\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\valko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(compare_classifiers(2, \"distance\", 20, \"rbf\", \"gini\", 19, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of text: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dataset length: 2285\n"
     ]
    }
   ],
   "source": [
    "y_test = test[\"SentimentoClassificacao\"].values\n",
    "x_test = test[\"Msg\"].values\n",
    "y_train = train[\"SentimentoClassificacao\"].values\n",
    "x_train = train[\"Msg\"].values\n",
    "\n",
    "print(f\"x_train dataset length: {len(x_train)}\")\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "x_train = vectorizer.fit_transform(x_train.astype(str))\n",
    "x_test = vectorizer.transform(x_test.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized x_train dataset length: 4456\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "print(f\"resized x_train dataset length: {x_train.shape[0]}\")\n",
    "x_train_2, x_val, y_train_2, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN for k=1 and w=uniform: 63.23%\n",
      "Accuracy of KNN for k=1 and w=distance: 63.23%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=2 and w=uniform: 56.95%\n",
      "Accuracy of KNN for k=2 and w=distance: 59.19%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=3 and w=uniform: 57.51%\n",
      "Accuracy of KNN for k=3 and w=distance: 59.42%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=4 and w=uniform: 55.27%\n",
      "Accuracy of KNN for k=4 and w=distance: 58.18%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=5 and w=uniform: 54.26%\n",
      "Accuracy of KNN for k=5 and w=distance: 58.18%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=6 and w=uniform: 53.81%\n",
      "Accuracy of KNN for k=6 and w=distance: 58.18%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=7 and w=uniform: 54.26%\n",
      "Accuracy of KNN for k=7 and w=distance: 59.75%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=8 and w=uniform: 52.47%\n",
      "Accuracy of KNN for k=8 and w=distance: 57.85%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=9 and w=uniform: 51.91%\n",
      "Accuracy of KNN for k=9 and w=distance: 56.95%\n",
      "\n",
      "\n",
      "Accuracy of KNN for k=10 and w=uniform: 51.35%\n",
      "Accuracy of KNN for k=10 and w=distance: 57.96%\n",
      "\n",
      "\n",
      "The best hyperparameters for TF-IDF are k=1 & w=distance with 63.0%\n",
      "-------------\n",
      "Accuracy of SVM for c=1 and kernel=linear: 52.13%\n",
      "Accuracy of SVM for c=1 and kernel=poly: 61.66%\n",
      "Accuracy of SVM for c=1 and kernel=rbf: 63.9%\n",
      "Accuracy of SVM for c=1 and kernel=sigmoid: 40.92%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=2 and kernel=linear: 51.35%\n",
      "Accuracy of SVM for c=2 and kernel=poly: 62.44%\n",
      "Accuracy of SVM for c=2 and kernel=rbf: 66.37%\n",
      "Accuracy of SVM for c=2 and kernel=sigmoid: 41.37%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=3 and kernel=linear: 51.79%\n",
      "Accuracy of SVM for c=3 and kernel=poly: 62.67%\n",
      "Accuracy of SVM for c=3 and kernel=rbf: 65.81%\n",
      "Accuracy of SVM for c=3 and kernel=sigmoid: 38.12%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=4 and kernel=linear: 52.8%\n",
      "Accuracy of SVM for c=4 and kernel=poly: 63.12%\n",
      "Accuracy of SVM for c=4 and kernel=rbf: 66.37%\n",
      "Accuracy of SVM for c=4 and kernel=sigmoid: 39.46%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=5 and kernel=linear: 52.91%\n",
      "Accuracy of SVM for c=5 and kernel=poly: 63.45%\n",
      "Accuracy of SVM for c=5 and kernel=rbf: 66.48%\n",
      "Accuracy of SVM for c=5 and kernel=sigmoid: 37.78%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=6 and kernel=linear: 53.36%\n",
      "Accuracy of SVM for c=6 and kernel=poly: 63.23%\n",
      "Accuracy of SVM for c=6 and kernel=rbf: 66.37%\n",
      "Accuracy of SVM for c=6 and kernel=sigmoid: 37.0%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=7 and kernel=linear: 52.8%\n",
      "Accuracy of SVM for c=7 and kernel=poly: 62.89%\n",
      "Accuracy of SVM for c=7 and kernel=rbf: 66.93%\n",
      "Accuracy of SVM for c=7 and kernel=sigmoid: 36.66%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=8 and kernel=linear: 52.8%\n",
      "Accuracy of SVM for c=8 and kernel=poly: 63.0%\n",
      "Accuracy of SVM for c=8 and kernel=rbf: 66.93%\n",
      "Accuracy of SVM for c=8 and kernel=sigmoid: 36.66%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=9 and kernel=linear: 52.91%\n",
      "Accuracy of SVM for c=9 and kernel=poly: 63.12%\n",
      "Accuracy of SVM for c=9 and kernel=rbf: 66.82%\n",
      "Accuracy of SVM for c=9 and kernel=sigmoid: 36.43%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=10 and kernel=linear: 53.14%\n",
      "Accuracy of SVM for c=10 and kernel=poly: 62.78%\n",
      "Accuracy of SVM for c=10 and kernel=rbf: 66.7%\n",
      "Accuracy of SVM for c=10 and kernel=sigmoid: 35.31%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=11 and kernel=linear: 53.03%\n",
      "Accuracy of SVM for c=11 and kernel=poly: 62.67%\n",
      "Accuracy of SVM for c=11 and kernel=rbf: 66.37%\n",
      "Accuracy of SVM for c=11 and kernel=sigmoid: 36.43%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=12 and kernel=linear: 53.36%\n",
      "Accuracy of SVM for c=12 and kernel=poly: 62.78%\n",
      "Accuracy of SVM for c=12 and kernel=rbf: 66.37%\n",
      "Accuracy of SVM for c=12 and kernel=sigmoid: 34.87%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=13 and kernel=linear: 53.14%\n",
      "Accuracy of SVM for c=13 and kernel=poly: 62.78%\n",
      "Accuracy of SVM for c=13 and kernel=rbf: 66.26%\n",
      "Accuracy of SVM for c=13 and kernel=sigmoid: 39.57%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=14 and kernel=linear: 52.91%\n",
      "Accuracy of SVM for c=14 and kernel=poly: 62.78%\n",
      "Accuracy of SVM for c=14 and kernel=rbf: 66.26%\n",
      "Accuracy of SVM for c=14 and kernel=sigmoid: 38.68%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=15 and kernel=linear: 52.91%\n",
      "Accuracy of SVM for c=15 and kernel=poly: 62.78%\n",
      "Accuracy of SVM for c=15 and kernel=rbf: 65.92%\n",
      "Accuracy of SVM for c=15 and kernel=sigmoid: 37.56%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=16 and kernel=linear: 52.69%\n",
      "Accuracy of SVM for c=16 and kernel=poly: 62.89%\n",
      "Accuracy of SVM for c=16 and kernel=rbf: 65.81%\n",
      "Accuracy of SVM for c=16 and kernel=sigmoid: 36.21%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=17 and kernel=linear: 52.69%\n",
      "Accuracy of SVM for c=17 and kernel=poly: 63.0%\n",
      "Accuracy of SVM for c=17 and kernel=rbf: 65.81%\n",
      "Accuracy of SVM for c=17 and kernel=sigmoid: 37.78%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=18 and kernel=linear: 52.8%\n",
      "Accuracy of SVM for c=18 and kernel=poly: 63.0%\n",
      "Accuracy of SVM for c=18 and kernel=rbf: 65.7%\n",
      "Accuracy of SVM for c=18 and kernel=sigmoid: 38.12%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=19 and kernel=linear: 52.47%\n",
      "Accuracy of SVM for c=19 and kernel=poly: 63.12%\n",
      "Accuracy of SVM for c=19 and kernel=rbf: 65.7%\n",
      "Accuracy of SVM for c=19 and kernel=sigmoid: 36.32%\n",
      "\n",
      "\n",
      "Accuracy of SVM for c=20 and kernel=linear: 52.47%\n",
      "Accuracy of SVM for c=20 and kernel=poly: 63.12%\n",
      "Accuracy of SVM for c=20 and kernel=rbf: 65.58%\n",
      "Accuracy of SVM for c=20 and kernel=sigmoid: 36.77%\n",
      "\n",
      "\n",
      "The best hyperparameters for TF-IDF are c=8 & kernel=rbf with 66.93%\n",
      "-------------\n",
      "Accuracy for criterion=gini and depth=1: 27.58%\n",
      "Accuracy for criterion=gini and depth=2: 34.08%\n",
      "Accuracy for criterion=gini and depth=3: 36.66%\n",
      "Accuracy for criterion=gini and depth=4: 36.77%\n",
      "Accuracy for criterion=gini and depth=5: 39.8%\n",
      "Accuracy for criterion=gini and depth=6: 43.27%\n",
      "Accuracy for criterion=gini and depth=7: 43.16%\n",
      "Accuracy for criterion=gini and depth=8: 46.52%\n",
      "Accuracy for criterion=gini and depth=9: 47.53%\n",
      "Accuracy for criterion=gini and depth=10: 49.55%\n",
      "Accuracy for criterion=gini and depth=11: 50.22%\n",
      "Accuracy for criterion=gini and depth=12: 51.23%\n",
      "Accuracy for criterion=gini and depth=13: 51.68%\n",
      "Accuracy for criterion=gini and depth=14: 49.78%\n",
      "Accuracy for criterion=gini and depth=15: 51.01%\n",
      "Accuracy for criterion=gini and depth=16: 53.03%\n",
      "Accuracy for criterion=gini and depth=17: 53.92%\n",
      "Accuracy for criterion=gini and depth=18: 55.27%\n",
      "Accuracy for criterion=gini and depth=19: 55.83%\n",
      "Accuracy for criterion=gini and depth=20: 56.05%\n",
      "\n",
      "\n",
      "Accuracy for criterion=entropy and depth=1: 30.83%\n",
      "Accuracy for criterion=entropy and depth=2: 34.19%\n",
      "Accuracy for criterion=entropy and depth=3: 36.88%\n",
      "Accuracy for criterion=entropy and depth=4: 37.0%\n",
      "Accuracy for criterion=entropy and depth=5: 38.79%\n",
      "Accuracy for criterion=entropy and depth=6: 42.38%\n",
      "Accuracy for criterion=entropy and depth=7: 46.64%\n",
      "Accuracy for criterion=entropy and depth=8: 48.21%\n",
      "Accuracy for criterion=entropy and depth=9: 49.22%\n",
      "Accuracy for criterion=entropy and depth=10: 49.66%\n",
      "Accuracy for criterion=entropy and depth=11: 51.01%\n",
      "Accuracy for criterion=entropy and depth=12: 52.02%\n",
      "Accuracy for criterion=entropy and depth=13: 53.03%\n",
      "Accuracy for criterion=entropy and depth=14: 52.24%\n",
      "Accuracy for criterion=entropy and depth=15: 53.48%\n",
      "Accuracy for criterion=entropy and depth=16: 54.6%\n",
      "Accuracy for criterion=entropy and depth=17: 55.38%\n",
      "Accuracy for criterion=entropy and depth=18: 57.06%\n",
      "Accuracy for criterion=entropy and depth=19: 56.84%\n",
      "Accuracy for criterion=entropy and depth=20: 56.95%\n",
      "\n",
      "\n",
      "Accuracy for criterion=log_loss and depth=1: 30.83%\n",
      "Accuracy for criterion=log_loss and depth=2: 34.19%\n",
      "Accuracy for criterion=log_loss and depth=3: 36.88%\n",
      "Accuracy for criterion=log_loss and depth=4: 37.0%\n",
      "Accuracy for criterion=log_loss and depth=5: 38.79%\n",
      "Accuracy for criterion=log_loss and depth=6: 42.26%\n",
      "Accuracy for criterion=log_loss and depth=7: 46.52%\n",
      "Accuracy for criterion=log_loss and depth=8: 48.32%\n",
      "Accuracy for criterion=log_loss and depth=9: 48.77%\n",
      "Accuracy for criterion=log_loss and depth=10: 49.66%\n",
      "Accuracy for criterion=log_loss and depth=11: 50.45%\n",
      "Accuracy for criterion=log_loss and depth=12: 52.13%\n",
      "Accuracy for criterion=log_loss and depth=13: 52.8%\n",
      "Accuracy for criterion=log_loss and depth=14: 52.24%\n",
      "Accuracy for criterion=log_loss and depth=15: 53.03%\n",
      "Accuracy for criterion=log_loss and depth=16: 54.04%\n",
      "Accuracy for criterion=log_loss and depth=17: 55.72%\n",
      "Accuracy for criterion=log_loss and depth=18: 55.72%\n",
      "Accuracy for criterion=log_loss and depth=19: 55.83%\n",
      "Accuracy for criterion=log_loss and depth=20: 57.62%\n",
      "\n",
      "\n",
      "The best hyperparameters for TF-IDF are criterion=log_loss & depth=20 with 57.74%\n"
     ]
    }
   ],
   "source": [
    "weights = ['uniform', 'distance']\n",
    "for k in range(1, 11):\n",
    "    for w in weights:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "        clf.fit(x_train_2, y_train_2)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        accuracy = round(accuracy_score(y_val, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of KNN for k={k} and w={w}: {accuracy}%\")\n",
    "    print(\"\\n\")\n",
    "print(\"The best hyperparameters for TF-IDF are k=1 & w=distance with 63.0%\")\n",
    "print(\"-------------\")\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for c in range(1, 21):\n",
    "    for k in kernels:\n",
    "        clf = SVC(C=c, kernel=k)\n",
    "        clf.fit(x_train_2, y_train_2)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        accuracy = round(accuracy_score(y_val, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of SVM for c={c} and kernel={k}: {accuracy}%\")\n",
    "    print(\"\\n\")\n",
    "print(\"The best hyperparameters for TF-IDF are c=8 & kernel=rbf with 66.93%\")\n",
    "print(\"-------------\")\n",
    "\n",
    "criterions = ['gini', 'entropy', 'log_loss']\n",
    "for criterion in criterions:\n",
    "\tfor depth in range(1, 21):\n",
    "\t\ttree = DecisionTreeClassifier(criterion=criterion, max_depth=depth)\n",
    "\t\ttree.fit(x_train_2, y_train_2)\n",
    "\t\ty_pred = tree.predict(x_val)\n",
    "\t\taccuracy = round(accuracy_score(y_val, y_pred)*100, 2)\n",
    "\t\tprint(f\"Accuracy for criterion={criterion} and depth={depth}: {accuracy}%\")\n",
    "\tprint(\"\\n\")\n",
    "print(\"The best hyperparameters for TF-IDF are criterion=log_loss & depth=20 with 57.74%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 37.27%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.33      0.27      0.29       292\n",
      "          -1       0.37      0.38      0.38       449\n",
      "           0       0.56      0.41      0.47       936\n",
      "           1       0.15      0.33      0.21       228\n",
      "\n",
      "    accuracy                           0.37      1905\n",
      "   macro avg       0.35      0.35      0.34      1905\n",
      "weighted avg       0.43      0.37      0.39      1905\n",
      "\n",
      "Accuracy of SVM: 40.84%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.41      0.32      0.36       292\n",
      "          -1       0.44      0.33      0.38       449\n",
      "           0       0.60      0.46      0.52       936\n",
      "           1       0.17      0.45      0.24       228\n",
      "\n",
      "    accuracy                           0.41      1905\n",
      "   macro avg       0.40      0.39      0.38      1905\n",
      "weighted avg       0.48      0.41      0.43      1905\n",
      "\n",
      "Accuracy of tree: 29.34%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.37      0.26      0.31       292\n",
      "          -1       0.42      0.32      0.36       449\n",
      "           0       0.50      0.20      0.29       936\n",
      "           1       0.15      0.66      0.25       228\n",
      "\n",
      "    accuracy                           0.29      1905\n",
      "   macro avg       0.36      0.36      0.30      1905\n",
      "weighted avg       0.42      0.29      0.30      1905\n",
      "\n",
      "Accuracy for Random Forest: 29.34%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.34      0.28      0.30       292\n",
      "          -1       0.41      0.35      0.38       449\n",
      "           0       0.61      0.47      0.53       936\n",
      "           1       0.19      0.46      0.27       228\n",
      "\n",
      "    accuracy                           0.41      1905\n",
      "   macro avg       0.39      0.39      0.37      1905\n",
      "weighted avg       0.47      0.41      0.43      1905\n",
      "\n",
      "Accuracy for Bagging: 40.05%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.41      0.32      0.36       292\n",
      "          -1       0.37      0.31      0.34       449\n",
      "           0       0.61      0.45      0.52       936\n",
      "           1       0.18      0.48      0.26       228\n",
      "\n",
      "    accuracy                           0.40      1905\n",
      "   macro avg       0.39      0.39      0.37      1905\n",
      "weighted avg       0.47      0.40      0.42      1905\n",
      "\n",
      "Accuracy for Logistic: 41.52%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.41      0.46      0.43       292\n",
      "          -1       0.40      0.37      0.39       449\n",
      "           0       0.71      0.38      0.50       936\n",
      "           1       0.20      0.59      0.30       228\n",
      "\n",
      "    accuracy                           0.42      1905\n",
      "   macro avg       0.43      0.45      0.40      1905\n",
      "weighted avg       0.53      0.42      0.44      1905\n",
      "\n",
      "Accuracy for Perceptron: 29.03%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.29      0.48      0.36       292\n",
      "          -1       0.29      0.14      0.19       449\n",
      "           0       0.51      0.21      0.30       936\n",
      "           1       0.19      0.66      0.29       228\n",
      "\n",
      "    accuracy                           0.29      1905\n",
      "   macro avg       0.32      0.37      0.28      1905\n",
      "weighted avg       0.38      0.29      0.28      1905\n",
      "\n",
      "Accuracy of bernoulliNB: 30.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.45      0.34      0.39       292\n",
      "          -1       0.34      0.18      0.24       449\n",
      "           0       0.78      0.21      0.34       936\n",
      "           1       0.16      0.86      0.28       228\n",
      "\n",
      "    accuracy                           0.30      1905\n",
      "   macro avg       0.43      0.40      0.31      1905\n",
      "weighted avg       0.55      0.30      0.31      1905\n",
      "\n",
      "Accuracy of multinomialNB: 38.11%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.29      0.55      0.38       292\n",
      "          -1       0.34      0.18      0.23       449\n",
      "           0       0.73      0.41      0.53       936\n",
      "           1       0.17      0.43      0.25       228\n",
      "\n",
      "    accuracy                           0.38      1905\n",
      "   macro avg       0.38      0.39      0.35      1905\n",
      "weighted avg       0.50      0.38      0.40      1905\n",
      "\n",
      "Accuracy for Stacking: 43.62%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.45      0.32      0.37       292\n",
      "          -1       0.43      0.38      0.40       449\n",
      "           0       0.67      0.49      0.56       936\n",
      "           1       0.18      0.50      0.27       228\n",
      "\n",
      "    accuracy                           0.44      1905\n",
      "   macro avg       0.43      0.42      0.40      1905\n",
      "weighted avg       0.52      0.44      0.46      1905\n",
      "\n",
      "Accuracy of gaussianNB: 29.34%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.27      0.52      0.35       292\n",
      "          -1       0.36      0.04      0.07       449\n",
      "           0       0.73      0.22      0.34       936\n",
      "           1       0.18      0.79      0.29       228\n",
      "\n",
      "    accuracy                           0.29      1905\n",
      "   macro avg       0.38      0.39      0.27      1905\n",
      "weighted avg       0.50      0.29      0.27      1905\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(compare_classifiers(1, \"distance\", 8, \"rbf\", \"log_loss\", 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv Pycharm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
