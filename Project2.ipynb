{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# AI models\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "test = pd.read_excel(\"data\\\\test.xlsx\")\n",
    "test['Msg'] = test['Msg'].apply(clean_text)\n",
    "\n",
    "train = pd.read_excel(\"data\\\\train.xlsx\")\n",
    "train['Msg'] = train['Msg'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentoClassificacao\n",
      " 0    1114\n",
      "-1     653\n",
      "-2     262\n",
      " 1     256\n",
      "Name: count, dtype: int64\n",
      "-------------------\n",
      "SentimentoClassificacao\n",
      " 0    936\n",
      "-1    449\n",
      "-2    292\n",
      " 1    228\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['SentimentoClassificacao'].value_counts())\n",
    "print(\"-------------------\")\n",
    "print(test['SentimentoClassificacao'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog_ID                  0\n",
      "SentimentoRegressao        0\n",
      "SentimentoClassificacao    0\n",
      "Msg                        0\n",
      "dtype: int64\n",
      "----------------------\n",
      "Dialog_ID                  0\n",
      "Msg                        0\n",
      "Anotador1                  6\n",
      "Anotador2                  2\n",
      "SentimentoRegressao        0\n",
      "SentimentoClassificacao    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = train.isna().sum()\n",
    "print(nan_counts)\n",
    "print(\"----------------------\")\n",
    "nan_counts = test.isna().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dataset length: 2285\n",
      "resized x_train dataset length: 4456\n"
     ]
    }
   ],
   "source": [
    "y_train = train[\"SentimentoClassificacao\"].values\n",
    "x_train = train[\"Msg\"].values\n",
    "print(f\"x_train dataset length: {len(x_train)}\")\n",
    "\n",
    "y_test = test[\"SentimentoClassificacao\"].values\n",
    "x_test = test[\"Msg\"].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "x_train = vectorizer.fit_transform(x_train.astype(str))\n",
    "x_test = vectorizer.transform(x_test.astype(str))\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "print(f\"resized x_train dataset length: {x_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN for k=1 and w=uniform: 37.38%\n",
      "Accuracy of KNN for k=1 and w=distance: 37.38%\n",
      "\n",
      "Accuracy of KNN for k=2 and w=uniform: 32.97%\n",
      "Accuracy of KNN for k=2 and w=distance: 36.06%\n",
      "\n",
      "Accuracy of KNN for k=3 and w=uniform: 33.39%\n",
      "Accuracy of KNN for k=3 and w=distance: 36.27%\n",
      "\n",
      "Accuracy of KNN for k=4 and w=uniform: 31.76%\n",
      "Accuracy of KNN for k=4 and w=distance: 33.7%\n",
      "\n",
      "Accuracy of KNN for k=5 and w=uniform: 26.82%\n",
      "Accuracy of KNN for k=5 and w=distance: 32.07%\n",
      "\n",
      "Accuracy of KNN for k=6 and w=uniform: 26.82%\n",
      "Accuracy of KNN for k=6 and w=distance: 31.34%\n",
      "\n",
      "Accuracy of KNN for k=7 and w=uniform: 28.24%\n",
      "Accuracy of KNN for k=7 and w=distance: 30.97%\n",
      "\n",
      "Accuracy of KNN for k=8 and w=uniform: 28.08%\n",
      "Accuracy of KNN for k=8 and w=distance: 30.55%\n",
      "\n",
      "Accuracy of KNN for k=9 and w=uniform: 29.29%\n",
      "Accuracy of KNN for k=9 and w=distance: 31.34%\n",
      "\n",
      "Accuracy of KNN for k=10 and w=uniform: 30.29%\n",
      "Accuracy of KNN for k=10 and w=distance: 32.18%\n",
      "\n",
      "Best hyperparameters: k=9 & w=distance.\n"
     ]
    }
   ],
   "source": [
    "weights = ['uniform', 'distance']\n",
    "for k in range(1, 11):\n",
    "    for w in weights:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of KNN for k={k} and w={w}: {accuracy}%\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Best hyperparameters: k=9 & w=distance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM for c=1 and kernel=linear: 39.9%\n",
      "Accuracy of SVM for c=1 and kernel=poly: 36.01%\n",
      "Accuracy of SVM for c=1 and kernel=rbf: 43.31%\n",
      "Accuracy of SVM for c=1 and kernel=sigmoid: 33.39%\n",
      "\n",
      "Accuracy of SVM for c=2 and kernel=linear: 39.16%\n",
      "Accuracy of SVM for c=2 and kernel=poly: 36.01%\n",
      "Accuracy of SVM for c=2 and kernel=rbf: 42.99%\n",
      "Accuracy of SVM for c=2 and kernel=sigmoid: 36.54%\n",
      "\n",
      "Accuracy of SVM for c=3 and kernel=linear: 37.95%\n",
      "Accuracy of SVM for c=3 and kernel=poly: 35.54%\n",
      "Accuracy of SVM for c=3 and kernel=rbf: 41.89%\n",
      "Accuracy of SVM for c=3 and kernel=sigmoid: 30.24%\n",
      "\n",
      "Accuracy of SVM for c=4 and kernel=linear: 37.9%\n",
      "Accuracy of SVM for c=4 and kernel=poly: 35.64%\n",
      "Accuracy of SVM for c=4 and kernel=rbf: 41.05%\n",
      "Accuracy of SVM for c=4 and kernel=sigmoid: 30.6%\n",
      "\n",
      "Accuracy of SVM for c=5 and kernel=linear: 37.59%\n",
      "Accuracy of SVM for c=5 and kernel=poly: 35.75%\n",
      "Accuracy of SVM for c=5 and kernel=rbf: 40.94%\n",
      "Accuracy of SVM for c=5 and kernel=sigmoid: 32.13%\n",
      "\n",
      "Accuracy of SVM for c=6 and kernel=linear: 37.43%\n",
      "Accuracy of SVM for c=6 and kernel=poly: 35.7%\n",
      "Accuracy of SVM for c=6 and kernel=rbf: 40.89%\n",
      "Accuracy of SVM for c=6 and kernel=sigmoid: 32.65%\n",
      "\n",
      "Accuracy of SVM for c=7 and kernel=linear: 37.64%\n",
      "Accuracy of SVM for c=7 and kernel=poly: 35.85%\n",
      "Accuracy of SVM for c=7 and kernel=rbf: 40.89%\n",
      "Accuracy of SVM for c=7 and kernel=sigmoid: 30.5%\n",
      "\n",
      "Accuracy of SVM for c=8 and kernel=linear: 37.8%\n",
      "Accuracy of SVM for c=8 and kernel=poly: 35.7%\n",
      "Accuracy of SVM for c=8 and kernel=rbf: 40.84%\n",
      "Accuracy of SVM for c=8 and kernel=sigmoid: 33.49%\n",
      "\n",
      "Accuracy of SVM for c=9 and kernel=linear: 37.48%\n",
      "Accuracy of SVM for c=9 and kernel=poly: 35.49%\n",
      "Accuracy of SVM for c=9 and kernel=rbf: 40.73%\n",
      "Accuracy of SVM for c=9 and kernel=sigmoid: 31.39%\n",
      "\n",
      "Accuracy of SVM for c=10 and kernel=linear: 37.64%\n",
      "Accuracy of SVM for c=10 and kernel=poly: 35.59%\n",
      "Accuracy of SVM for c=10 and kernel=rbf: 40.68%\n",
      "Accuracy of SVM for c=10 and kernel=sigmoid: 30.08%\n",
      "\n",
      "Best hyperparameters: c=1 & kernel=rbf.\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for c in range(1, 11):\n",
    "    for k in kernels:\n",
    "        clf = SVC(C=c, kernel=k)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of SVM for c={c} and kernel={k}: {accuracy}%\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Best hyperparameters: c=1 & kernel=rbf.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for criterion=gini and depth=1: 24.15%\n",
      "Accuracy for criterion=gini and depth=2: 48.45%\n",
      "Accuracy for criterion=gini and depth=3: 48.35%\n",
      "Accuracy for criterion=gini and depth=4: 48.56%\n",
      "Accuracy for criterion=gini and depth=5: 45.3%\n",
      "Accuracy for criterion=gini and depth=6: 53.12%\n",
      "Accuracy for criterion=gini and depth=7: 55.07%\n",
      "Accuracy for criterion=gini and depth=8: 54.96%\n",
      "Accuracy for criterion=gini and depth=9: 54.59%\n",
      "Accuracy for criterion=gini and depth=10: 52.39%\n",
      "\n",
      "Accuracy for criterion=entropy and depth=1: 49.71%\n",
      "Accuracy for criterion=entropy and depth=2: 50.03%\n",
      "Accuracy for criterion=entropy and depth=3: 50.24%\n",
      "Accuracy for criterion=entropy and depth=4: 49.87%\n",
      "Accuracy for criterion=entropy and depth=5: 48.14%\n",
      "Accuracy for criterion=entropy and depth=6: 45.41%\n",
      "Accuracy for criterion=entropy and depth=7: 52.39%\n",
      "Accuracy for criterion=entropy and depth=8: 53.65%\n",
      "Accuracy for criterion=entropy and depth=9: 55.85%\n",
      "Accuracy for criterion=entropy and depth=10: 52.81%\n",
      "\n",
      "Accuracy for criterion=log_loss and depth=1: 49.71%\n",
      "Accuracy for criterion=log_loss and depth=2: 50.03%\n",
      "Accuracy for criterion=log_loss and depth=3: 50.13%\n",
      "Accuracy for criterion=log_loss and depth=4: 49.97%\n",
      "Accuracy for criterion=log_loss and depth=5: 48.14%\n",
      "Accuracy for criterion=log_loss and depth=6: 45.2%\n",
      "Accuracy for criterion=log_loss and depth=7: 52.23%\n",
      "Accuracy for criterion=log_loss and depth=8: 54.07%\n",
      "Accuracy for criterion=log_loss and depth=9: 55.54%\n",
      "Accuracy for criterion=log_loss and depth=10: 52.86%\n",
      "\n",
      "Best hyperparameters: criterion=log_loss & depth=3.\n"
     ]
    }
   ],
   "source": [
    "criterions = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "for criterion in criterions:\n",
    "\tfor depth in range(1, 11):\n",
    "\t\ttree = DecisionTreeClassifier(criterion=criterion, max_depth=depth)\n",
    "\t\ttree.fit(x_train, y_train)\n",
    "\t\ty_pred = tree.predict(x_test)\n",
    "\t\taccuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\t\tprint(f\"Accuracy for criterion={criterion} and depth={depth}: {accuracy}%\")\n",
    "\tprint(\"\")\n",
    "\n",
    "print(\"Best hyperparameters: criterion=log_loss & depth=3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 52.86%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.34      0.27      0.30       292\n",
      "          -1       0.41      0.34      0.37       449\n",
      "           0       0.61      0.48      0.53       936\n",
      "           1       0.19      0.47      0.28       228\n",
      "\n",
      "    accuracy                           0.41      1905\n",
      "   macro avg       0.39      0.39      0.37      1905\n",
      "weighted avg       0.47      0.41      0.43      1905\n",
      "\n",
      "Accuracy for Bagging: 39.9%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.41      0.28      0.33       292\n",
      "          -1       0.38      0.32      0.35       449\n",
      "           0       0.59      0.45      0.51       936\n",
      "           1       0.18      0.49      0.27       228\n",
      "\n",
      "    accuracy                           0.40      1905\n",
      "   macro avg       0.39      0.38      0.36      1905\n",
      "weighted avg       0.46      0.40      0.42      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)\n",
    "accuracy_rf = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "print(f\"Accuracy for Random Forest: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Bagging Classifier\n",
    "bagging = BaggingClassifier()\n",
    "bagging.fit(x_train, y_train)\n",
    "y_pred_bagging = bagging.predict(x_test)\n",
    "accuracy_bagging = round(accuracy_score(y_test, y_pred_bagging) * 100, 2)\n",
    "print(f\"Accuracy for Bagging: {accuracy_bagging}%\")\n",
    "print(classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic: 40.21%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.40      0.45      0.42       292\n",
      "          -1       0.40      0.32      0.35       449\n",
      "           0       0.72      0.38      0.50       936\n",
      "           1       0.19      0.59      0.28       228\n",
      "\n",
      "    accuracy                           0.40      1905\n",
      "   macro avg       0.43      0.43      0.39      1905\n",
      "weighted avg       0.53      0.40      0.43      1905\n",
      "\n",
      "Accuracy for Perceptron: 31.6%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.30      0.44      0.36       292\n",
      "          -1       0.32      0.22      0.26       449\n",
      "           0       0.58      0.28      0.38       936\n",
      "           1       0.16      0.50      0.24       228\n",
      "\n",
      "    accuracy                           0.32      1905\n",
      "   macro avg       0.34      0.36      0.31      1905\n",
      "weighted avg       0.42      0.32      0.33      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(x_train, y_train)\n",
    "y_pred = logistic.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy for Logistic: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train, y_train)\n",
    "y_pred = perceptron.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy for Perceptron: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 31.34%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.30      0.30      0.30       292\n",
      "          -1       0.28      0.40      0.33       449\n",
      "           0       0.53      0.27      0.36       936\n",
      "           1       0.16      0.34      0.22       228\n",
      "\n",
      "    accuracy                           0.31      1905\n",
      "   macro avg       0.32      0.33      0.30      1905\n",
      "weighted avg       0.39      0.31      0.32      1905\n",
      "\n",
      "Accuracy of SVM: 43.31%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.49      0.26      0.34       292\n",
      "          -1       0.45      0.42      0.44       449\n",
      "           0       0.68      0.48      0.56       936\n",
      "           1       0.17      0.51      0.26       228\n",
      "\n",
      "    accuracy                           0.43      1905\n",
      "   macro avg       0.45      0.42      0.40      1905\n",
      "weighted avg       0.54      0.43      0.46      1905\n",
      "\n",
      "Accuracy of tree: 50.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.56      0.05      0.09       292\n",
      "          -1       1.00      0.00      0.01       449\n",
      "           0       0.50      0.99      0.67       936\n",
      "           1       0.50      0.06      0.11       228\n",
      "\n",
      "    accuracy                           0.50      1905\n",
      "   macro avg       0.64      0.28      0.22      1905\n",
      "weighted avg       0.63      0.50      0.36      1905\n",
      "\n",
      "Accuracy of bernoulliNB: 30.34%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.46      0.35      0.40       292\n",
      "          -1       0.34      0.18      0.24       449\n",
      "           0       0.78      0.21      0.33       936\n",
      "           1       0.16      0.86      0.28       228\n",
      "\n",
      "    accuracy                           0.30      1905\n",
      "   macro avg       0.44      0.40      0.31      1905\n",
      "weighted avg       0.55      0.30      0.31      1905\n",
      "\n",
      "Accuracy of multinomialNB: 38.43%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.29      0.56      0.38       292\n",
      "          -1       0.36      0.19      0.25       449\n",
      "           0       0.73      0.41      0.53       936\n",
      "           1       0.17      0.43      0.24       228\n",
      "\n",
      "    accuracy                           0.38      1905\n",
      "   macro avg       0.39      0.40      0.35      1905\n",
      "weighted avg       0.51      0.38      0.41      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST THE HYPERPARAMETERS\n",
    "knn = KNeighborsClassifier(n_neighbors=9, weights=\"distance\")\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of KNN: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "svm = SVC(C=1, kernel=\"rbf\")\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of SVM: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion=\"log_loss\", max_depth=3)\n",
    "tree.fit(x_train, y_train)\n",
    "y_pred = tree.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of tree: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "bernoulli = BernoulliNB()\n",
    "bernoulli.fit(x_train, y_train)\n",
    "y_pred = bernoulli.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of bernoulliNB: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "multi = MultinomialNB()\n",
    "multi.fit(x_train, y_train)\n",
    "y_pred = multi.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of multinomialNB: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Stacking: 43.94%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.54      0.26      0.35       292\n",
      "          -1       0.46      0.42      0.44       449\n",
      "           0       0.68      0.49      0.57       936\n",
      "           1       0.17      0.51      0.26       228\n",
      "\n",
      "    accuracy                           0.44      1905\n",
      "   macro avg       0.46      0.42      0.40      1905\n",
      "weighted avg       0.55      0.44      0.47      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stacking Classifier (usando Logistic Regression y Random Forest como modelos base)\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logistic', LogisticRegression()),\t\t# 51.39% accuracy \n",
    "        ('svm', SVC(C=1, kernel=\"rbf\")),\t\t# 88% precision for -2\n",
    "        (\"tree\", DecisionTreeClassifier(criterion=\"log_loss\", max_depth=3)),\t# 42% precision for -1\n",
    "        (\"Bernoulli\", BernoulliNB()),\t\t\t# 75% precision for 0\n",
    "        (\"Multinomial\", MultinomialNB())\t\t# 70% precision for 1\n",
    "    ],\n",
    "    final_estimator=SVC(C=1, kernel=\"rbf\")\n",
    ")\n",
    "stacking.fit(x_train, y_train)\n",
    "y_pred_stacking = stacking.predict(x_test)\n",
    "accuracy_stacking = round(accuracy_score(y_test, y_pred_stacking) * 100, 2)\n",
    "print(f\"Accuracy for Stacking: {accuracy_stacking}%\")\n",
    "print(classification_report(y_test, y_pred_stacking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of gaussianNB: 29.19%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.26      0.52      0.35       292\n",
      "          -1       0.41      0.05      0.08       449\n",
      "           0       0.74      0.22      0.33       936\n",
      "           1       0.18      0.79      0.29       228\n",
      "\n",
      "    accuracy                           0.29      1905\n",
      "   macro avg       0.40      0.39      0.27      1905\n",
      "weighted avg       0.52      0.29      0.27      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_dense = x_train.toarray() if hasattr(x_train, \"toarray\") else x_train\n",
    "y_train_dense = y_train.toarray() if hasattr(y_train, \"toarray\") else y_train\n",
    "x_test_dense = x_test.toarray() if hasattr(x_test, \"toarray\") else x_test\n",
    "y_test_dense = y_test.toarray() if hasattr(y_test, \"toarray\") else y_test\n",
    "\n",
    "gauss = GaussianNB()\n",
    "gauss.fit(x_train_dense, y_train_dense)\n",
    "y_pred = gauss.predict(x_test_dense)\n",
    "accuracy = round(accuracy_score(y_test_dense, y_pred)*100, 2)\n",
    "print(f\"Accuracy of gaussianNB: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the best classfier is the Decision Tree with a 55.7% of accuracy using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x_train_bow = vectorizer.fit_transform(x_train)\n",
    "x_test_bow = vectorizer.transform(x_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
