{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# AI models\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bykon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "test = pd.read_excel(\"data\\\\test.xlsx\")\n",
    "test['Msg'] = test['Msg'].apply(clean_text)\n",
    "\n",
    "train = pd.read_excel(\"data\\\\train.xlsx\")\n",
    "train['Msg'] = train['Msg'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentoClassificacao\n",
      " 0    1114\n",
      "-1     653\n",
      "-2     262\n",
      " 1     256\n",
      "Name: count, dtype: int64\n",
      "-------------------\n",
      "SentimentoClassificacao\n",
      " 0    936\n",
      "-1    449\n",
      "-2    292\n",
      " 1    228\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['SentimentoClassificacao'].value_counts())\n",
    "print(\"-------------------\")\n",
    "print(test['SentimentoClassificacao'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog_ID                  0\n",
      "SentimentoRegressao        0\n",
      "SentimentoClassificacao    0\n",
      "Msg                        0\n",
      "dtype: int64\n",
      "----------------------\n",
      "Dialog_ID                  0\n",
      "Msg                        0\n",
      "Anotador1                  6\n",
      "Anotador2                  2\n",
      "SentimentoRegressao        0\n",
      "SentimentoClassificacao    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = train.isna().sum()\n",
    "print(nan_counts)\n",
    "print(\"----------------------\")\n",
    "nan_counts = test.isna().sum()\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dataset length: 2285\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dataset length: 2285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train = train[\"SentimentoClassificacao\"].values\n",
    "x_train = train[\"Msg\"].values\n",
    "print(f\"x_train dataset length: {len(x_train)}\")\n",
    "\n",
    "y_test = test[\"SentimentoClassificacao\"].values\n",
    "x_test = test[\"Msg\"].values\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "def get_bert_embedding(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]  \n",
    "    elif not isinstance(texts, list) or not all(isinstance(t, str) for t in texts):\n",
    "        raise ValueError(\"La entrada debe ser una cadena o una lista de cadenas.\")\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    cls_vectors = outputs.last_hidden_state[:, 0, :] \n",
    "    return cls_vectors\n",
    "x_train = x_train.tolist() if not isinstance(x_train, list) else x_train\n",
    "x_test = x_test.tolist() if not isinstance(x_test, list) else x_test\n",
    "x_train = get_bert_embedding(x_train)\n",
    "x_test = get_bert_embedding(x_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dataset length: 2285\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "y_train = train[\"SentimentoClassificacao\"].values\n",
    "x_train = train[\"Msg\"].values\n",
    "print(f\"x_train dataset length: {len(x_train)}\")\n",
    "\n",
    "y_test = test[\"SentimentoClassificacao\"].values\n",
    "x_test = test[\"Msg\"].values\n",
    "vectorizer = CountVectorizer()\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\bykon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dataset length: 2285\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "nltk.download('punkt_tab')\n",
    "y_train = train[\"SentimentoClassificacao\"].values\n",
    "x_train = train[\"Msg\"].values\n",
    "print(f\"x_train dataset length: {len(x_train)}\")\n",
    "\n",
    "y_test = test[\"SentimentoClassificacao\"].values\n",
    "x_test = test[\"Msg\"].values\n",
    "\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "train_sentences = [word_tokenize(text.lower()) for text in x_train]\n",
    "test_sentences = [word_tokenize(text.lower()) for text in x_test]\n",
    "model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "def get_sentence_vector(sentence):\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    word_vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "x_train = np.array([get_sentence_vector(text) for text in x_train])\n",
    "x_test = np.array([get_sentence_vector(text) for text in x_test])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_train = train[\"SentimentoClassificacao\"].values\\nx_train = train[\"Msg\"].values\\nprint(f\"x_train dataset length: {len(x_train)}\")\\n\\ny_test = test[\"SentimentoClassificacao\"].values\\nx_test = test[\"Msg\"].values\\n\\nvectorizer = TfidfVectorizer(max_features=100)\\nx_train = vectorizer.fit_transform(x_train.astype(str))\\nx_test = vectorizer.transform(x_test.astype(str))\\n\\nsmote = SMOTE(sampling_strategy=\\'auto\\', random_state=42)\\nx_train, y_train = smote.fit_resample(x_train, y_train)\\nprint(f\"resized x_train dataset length: {x_train.shape[0]}\")\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_train = train[\"SentimentoClassificacao\"].values\n",
    "x_train = train[\"Msg\"].values\n",
    "print(f\"x_train dataset length: {len(x_train)}\")\n",
    "\n",
    "y_test = test[\"SentimentoClassificacao\"].values\n",
    "x_test = test[\"Msg\"].values\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "x_train = vectorizer.fit_transform(x_train.astype(str))\n",
    "x_test = vectorizer.transform(x_test.astype(str))\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "print(f\"resized x_train dataset length: {x_train.shape[0]}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN for k=1 and w=uniform: 41.26%\n",
      "Accuracy of KNN for k=1 and w=distance: 41.26%\n",
      "\n",
      "Accuracy of KNN for k=2 and w=uniform: 44.67%\n",
      "Accuracy of KNN for k=2 and w=distance: 41.05%\n",
      "\n",
      "Accuracy of KNN for k=3 and w=uniform: 45.83%\n",
      "Accuracy of KNN for k=3 and w=distance: 47.35%\n",
      "\n",
      "Accuracy of KNN for k=4 and w=uniform: 45.51%\n",
      "Accuracy of KNN for k=4 and w=distance: 47.82%\n",
      "\n",
      "Accuracy of KNN for k=5 and w=uniform: 47.66%\n",
      "Accuracy of KNN for k=5 and w=distance: 47.51%\n",
      "\n",
      "Accuracy of KNN for k=6 and w=uniform: 46.72%\n",
      "Accuracy of KNN for k=6 and w=distance: 48.61%\n",
      "\n",
      "Accuracy of KNN for k=7 and w=uniform: 45.14%\n",
      "Accuracy of KNN for k=7 and w=distance: 47.93%\n",
      "\n",
      "Accuracy of KNN for k=8 and w=uniform: 46.88%\n",
      "Accuracy of KNN for k=8 and w=distance: 48.5%\n",
      "\n",
      "Accuracy of KNN for k=9 and w=uniform: 46.51%\n",
      "Accuracy of KNN for k=9 and w=distance: 48.45%\n",
      "\n",
      "Accuracy of KNN for k=10 and w=uniform: 47.66%\n",
      "Accuracy of KNN for k=10 and w=distance: 49.45%\n",
      "\n",
      "Best hyperparameters: k=9 & w=distance.\n"
     ]
    }
   ],
   "source": [
    "weights = ['uniform', 'distance']\n",
    "for k in range(1, 11):\n",
    "    for w in weights:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of KNN for k={k} and w={w}: {accuracy}%\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM for c=1 and kernel=linear: 43.99%\n",
      "Accuracy of SVM for c=1 and kernel=poly: 52.23%\n",
      "Accuracy of SVM for c=1 and kernel=rbf: 52.13%\n",
      "Accuracy of SVM for c=1 and kernel=sigmoid: 49.19%\n",
      "\n",
      "Accuracy of SVM for c=2 and kernel=linear: 42.2%\n",
      "Accuracy of SVM for c=2 and kernel=poly: 52.7%\n",
      "Accuracy of SVM for c=2 and kernel=rbf: 52.55%\n",
      "Accuracy of SVM for c=2 and kernel=sigmoid: 49.55%\n",
      "\n",
      "Accuracy of SVM for c=3 and kernel=linear: 41.52%\n",
      "Accuracy of SVM for c=3 and kernel=poly: 52.91%\n",
      "Accuracy of SVM for c=3 and kernel=rbf: 52.76%\n",
      "Accuracy of SVM for c=3 and kernel=sigmoid: 51.02%\n",
      "\n",
      "Accuracy of SVM for c=4 and kernel=linear: 39.53%\n",
      "Accuracy of SVM for c=4 and kernel=poly: 53.02%\n",
      "Accuracy of SVM for c=4 and kernel=rbf: 52.91%\n",
      "Accuracy of SVM for c=4 and kernel=sigmoid: 51.6%\n",
      "\n",
      "Accuracy of SVM for c=5 and kernel=linear: 38.74%\n",
      "Accuracy of SVM for c=5 and kernel=poly: 53.54%\n",
      "Accuracy of SVM for c=5 and kernel=rbf: 52.97%\n",
      "Accuracy of SVM for c=5 and kernel=sigmoid: 51.39%\n",
      "\n",
      "Accuracy of SVM for c=6 and kernel=linear: 38.43%\n",
      "Accuracy of SVM for c=6 and kernel=poly: 51.5%\n",
      "Accuracy of SVM for c=6 and kernel=rbf: 52.39%\n",
      "Accuracy of SVM for c=6 and kernel=sigmoid: 51.13%\n",
      "\n",
      "Accuracy of SVM for c=7 and kernel=linear: 38.64%\n",
      "Accuracy of SVM for c=7 and kernel=poly: 50.87%\n",
      "Accuracy of SVM for c=7 and kernel=rbf: 50.29%\n",
      "Accuracy of SVM for c=7 and kernel=sigmoid: 48.56%\n",
      "\n",
      "Accuracy of SVM for c=8 and kernel=linear: 38.9%\n",
      "Accuracy of SVM for c=8 and kernel=poly: 50.87%\n",
      "Accuracy of SVM for c=8 and kernel=rbf: 51.6%\n",
      "Accuracy of SVM for c=8 and kernel=sigmoid: 47.51%\n",
      "\n",
      "Accuracy of SVM for c=9 and kernel=linear: 38.11%\n",
      "Accuracy of SVM for c=9 and kernel=poly: 50.55%\n",
      "Accuracy of SVM for c=9 and kernel=rbf: 51.71%\n",
      "Accuracy of SVM for c=9 and kernel=sigmoid: 47.45%\n",
      "\n",
      "Accuracy of SVM for c=10 and kernel=linear: 38.01%\n",
      "Accuracy of SVM for c=10 and kernel=poly: 50.13%\n",
      "Accuracy of SVM for c=10 and kernel=rbf: 51.5%\n",
      "Accuracy of SVM for c=10 and kernel=sigmoid: 48.08%\n",
      "\n",
      "Best hyperparameters: c=1 & kernel=rbf.\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for c in range(1, 11):\n",
    "    for k in kernels:\n",
    "        clf = SVC(C=c, kernel=k)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "        print(f\"Accuracy of SVM for c={c} and kernel={k}: {accuracy}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for criterion=gini and depth=1: 49.13%\n",
      "Accuracy for criterion=gini and depth=2: 45.56%\n",
      "Accuracy for criterion=gini and depth=3: 45.2%\n",
      "Accuracy for criterion=gini and depth=4: 48.98%\n",
      "Accuracy for criterion=gini and depth=5: 46.67%\n",
      "Accuracy for criterion=gini and depth=6: 45.3%\n",
      "Accuracy for criterion=gini and depth=7: 44.09%\n",
      "Accuracy for criterion=gini and depth=8: 43.52%\n",
      "Accuracy for criterion=gini and depth=9: 38.43%\n",
      "Accuracy for criterion=gini and depth=10: 43.04%\n",
      "\n",
      "Accuracy for criterion=entropy and depth=1: 49.13%\n",
      "Accuracy for criterion=entropy and depth=2: 51.86%\n",
      "Accuracy for criterion=entropy and depth=3: 48.35%\n",
      "Accuracy for criterion=entropy and depth=4: 47.51%\n",
      "Accuracy for criterion=entropy and depth=5: 50.03%\n",
      "Accuracy for criterion=entropy and depth=6: 45.41%\n",
      "Accuracy for criterion=entropy and depth=7: 46.25%\n",
      "Accuracy for criterion=entropy and depth=8: 44.93%\n",
      "Accuracy for criterion=entropy and depth=9: 43.15%\n",
      "Accuracy for criterion=entropy and depth=10: 43.41%\n",
      "\n",
      "Accuracy for criterion=log_loss and depth=1: 49.13%\n",
      "Accuracy for criterion=log_loss and depth=2: 51.86%\n",
      "Accuracy for criterion=log_loss and depth=3: 48.35%\n",
      "Accuracy for criterion=log_loss and depth=4: 47.51%\n",
      "Accuracy for criterion=log_loss and depth=5: 50.18%\n",
      "Accuracy for criterion=log_loss and depth=6: 45.14%\n",
      "Accuracy for criterion=log_loss and depth=7: 45.98%\n",
      "Accuracy for criterion=log_loss and depth=8: 46.19%\n",
      "Accuracy for criterion=log_loss and depth=9: 41.47%\n",
      "Accuracy for criterion=log_loss and depth=10: 43.83%\n",
      "\n",
      "Best hyperparameters: criterion=log_loss & depth=3.\n"
     ]
    }
   ],
   "source": [
    "criterions = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "for criterion in criterions:\n",
    "\tfor depth in range(1, 11):\n",
    "\t\ttree = DecisionTreeClassifier(criterion=criterion, max_depth=depth)\n",
    "\t\ttree.fit(x_train, y_train)\n",
    "\t\ty_pred = tree.predict(x_test)\n",
    "\t\taccuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\t\tprint(f\"Accuracy for criterion={criterion} and depth={depth}: {accuracy}%\")\n",
    "\tprint(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 43.83%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.62      0.08      0.14       292\n",
      "          -1       0.39      0.34      0.36       449\n",
      "           0       0.56      0.87      0.68       936\n",
      "           1       0.21      0.03      0.05       228\n",
      "\n",
      "    accuracy                           0.52      1905\n",
      "   macro avg       0.45      0.33      0.31      1905\n",
      "weighted avg       0.49      0.52      0.45      1905\n",
      "\n",
      "Accuracy for Bagging: 43.62%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.36      0.12      0.18       292\n",
      "          -1       0.31      0.46      0.37       449\n",
      "           0       0.54      0.60      0.57       936\n",
      "           1       0.26      0.10      0.15       228\n",
      "\n",
      "    accuracy                           0.44      1905\n",
      "   macro avg       0.37      0.32      0.32      1905\n",
      "weighted avg       0.42      0.44      0.41      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)\n",
    "accuracy_rf = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "print(f\"Accuracy for Random Forest: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Bagging Classifier\n",
    "bagging = BaggingClassifier()\n",
    "bagging.fit(x_train, y_train)\n",
    "y_pred_bagging = bagging.predict(x_test)\n",
    "accuracy_bagging = round(accuracy_score(y_test, y_pred_bagging) * 100, 2)\n",
    "print(f\"Accuracy for Bagging: {accuracy_bagging}%\")\n",
    "print(classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic: 45.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.45      0.20      0.27       292\n",
      "          -1       0.31      0.36      0.33       449\n",
      "           0       0.55      0.66      0.60       936\n",
      "           1       0.23      0.14      0.17       228\n",
      "\n",
      "    accuracy                           0.46      1905\n",
      "   macro avg       0.38      0.34      0.35      1905\n",
      "weighted avg       0.44      0.46      0.44      1905\n",
      "\n",
      "Accuracy for Perceptron: 40.94%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.29      0.66      0.41       292\n",
      "          -1       0.18      0.07      0.10       449\n",
      "           0       0.58      0.54      0.56       936\n",
      "           1       0.24      0.20      0.22       228\n",
      "\n",
      "    accuracy                           0.41      1905\n",
      "   macro avg       0.32      0.37      0.32      1905\n",
      "weighted avg       0.40      0.41      0.39      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(x_train, y_train)\n",
    "y_pred = logistic.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy for Logistic: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train, y_train)\n",
    "y_pred = perceptron.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy for Perceptron: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 48.45%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.44      0.12      0.19       292\n",
      "          -1       0.32      0.37      0.34       449\n",
      "           0       0.57      0.75      0.65       936\n",
      "           1       0.30      0.09      0.14       228\n",
      "\n",
      "    accuracy                           0.48      1905\n",
      "   macro avg       0.41      0.33      0.33      1905\n",
      "weighted avg       0.46      0.48      0.44      1905\n",
      "\n",
      "Accuracy of SVM: 52.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00       292\n",
      "          -1       0.43      0.19      0.26       449\n",
      "           0       0.53      0.97      0.69       936\n",
      "           1       0.00      0.00      0.00       228\n",
      "\n",
      "    accuracy                           0.52      1905\n",
      "   macro avg       0.24      0.29      0.24      1905\n",
      "weighted avg       0.36      0.52      0.40      1905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of tree: 48.35%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00       292\n",
      "          -1       0.30      0.40      0.34       449\n",
      "           0       0.57      0.79      0.66       936\n",
      "           1       0.00      0.00      0.00       228\n",
      "\n",
      "    accuracy                           0.48      1905\n",
      "   macro avg       0.22      0.30      0.25      1905\n",
      "weighted avg       0.35      0.48      0.41      1905\n",
      "\n",
      "Accuracy of bernoulliNB: 42.31%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.34      0.45      0.39       292\n",
      "          -1       0.35      0.28      0.31       449\n",
      "           0       0.72      0.47      0.56       936\n",
      "           1       0.21      0.50      0.29       228\n",
      "\n",
      "    accuracy                           0.42      1905\n",
      "   macro avg       0.40      0.42      0.39      1905\n",
      "weighted avg       0.51      0.42      0.44      1905\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[0;32m     30\u001b[0m multi \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmulti\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m multi\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     33\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(accuracy_score(y_test, y_pred)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:772\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    770\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32mc:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:894\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    893\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 894\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultinomialNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bykon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1489\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "# TEST THE HYPERPARAMETERS\n",
    "knn = KNeighborsClassifier(n_neighbors=9, weights=\"distance\")\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of KNN: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "svm = SVC(C=1, kernel=\"rbf\")\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of SVM: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion=\"log_loss\", max_depth=3)\n",
    "tree.fit(x_train, y_train)\n",
    "y_pred = tree.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of tree: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "bernoulli = BernoulliNB()\n",
    "bernoulli.fit(x_train, y_train)\n",
    "y_pred = bernoulli.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of bernoulliNB: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "multi = MultinomialNB()\n",
    "multi.fit(x_train, y_train)\n",
    "y_pred = multi.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f\"Accuracy of multinomialNB: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Stacking: 52.49%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.93      0.04      0.08       292\n",
      "          -1       0.45      0.27      0.33       449\n",
      "           0       0.55      0.93      0.69       936\n",
      "           1       0.05      0.01      0.01       228\n",
      "\n",
      "    accuracy                           0.52      1905\n",
      "   macro avg       0.49      0.31      0.28      1905\n",
      "weighted avg       0.52      0.52      0.43      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stacking Classifier (usando Logistic Regression y Random Forest como modelos base)\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logistic', LogisticRegression()),\t\t# 51.39% accuracy \n",
    "        ('svm', SVC(C=1, kernel=\"rbf\")),\t\t# 88% precision for -2\n",
    "        (\"tree\", DecisionTreeClassifier(criterion=\"log_loss\", max_depth=3)),\t# 42% precision for -1\n",
    "        (\"Bernoulli\", BernoulliNB()),\t\t\t# 75% precision for 0\n",
    "        (\"Multinomial\", MultinomialNB())\t\t# 70% precision for 1\n",
    "    ],\n",
    "    final_estimator=SVC(C=1, kernel=\"rbf\")\n",
    ")\n",
    "stacking.fit(x_train, y_train)\n",
    "y_pred_stacking = stacking.predict(x_test)\n",
    "accuracy_stacking = round(accuracy_score(y_test, y_pred_stacking) * 100, 2)\n",
    "print(f\"Accuracy for Stacking: {accuracy_stacking}%\")\n",
    "print(classification_report(y_test, y_pred_stacking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of gaussianNB: 41.84%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.29      0.21      0.24       292\n",
      "          -1       0.32      0.44      0.37       449\n",
      "           0       0.58      0.47      0.52       936\n",
      "           1       0.31      0.41      0.35       228\n",
      "\n",
      "    accuracy                           0.42      1905\n",
      "   macro avg       0.37      0.38      0.37      1905\n",
      "weighted avg       0.44      0.42      0.42      1905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_dense = x_train.toarray() if hasattr(x_train, \"toarray\") else x_train\n",
    "y_train_dense = y_train.toarray() if hasattr(y_train, \"toarray\") else y_train\n",
    "x_test_dense = x_test.toarray() if hasattr(x_test, \"toarray\") else x_test\n",
    "y_test_dense = y_test.toarray() if hasattr(y_test, \"toarray\") else y_test\n",
    "\n",
    "gauss = GaussianNB()\n",
    "gauss.fit(x_train_dense, y_train_dense)\n",
    "y_pred = gauss.predict(x_test_dense)\n",
    "accuracy = round(accuracy_score(y_test_dense, y_pred)*100, 2)\n",
    "print(f\"Accuracy of gaussianNB: {accuracy}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the best classfier is the Decision Tree with a 55.7% of accuracy using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
